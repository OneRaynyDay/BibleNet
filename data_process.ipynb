{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Imports and Constants#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# Imports for the project #\n",
    "###########################\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import h5py\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "import pickle\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# Constants #\n",
    "#############\n",
    "\n",
    "word_sequence_dest = \"word_sequence.hdf5\"\n",
    "word_mapping_dest = \"word_map.pkl\"\n",
    "idx_mapping_dest = \"idx_map.pkl\"\n",
    "delims = ' |\\t|\\n|\\r\\n|:'\n",
    "prune_freq = 3 # the word must appear >5 times in the entire text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Acquire dataset #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already the .txt's of the bible in our own file directory. All we need to do is to read it. \n",
    "\n",
    "**Currently we are only reading in the English version.**\n",
    "\n",
    "**TODO: We don't have a \"proper\" tokenizer right now. We are just delimiting via spaces.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open('small_bible.txt', encoding='utf-8') as f:\n",
    "    #bible = re.split(delims, f.read())\n",
    "    f_str = unidecode(f.read())\n",
    "    bible = word_tokenize(f_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['because', 'that', 'in', 'it', 'he', 'had', 'rested', 'from', 'all', 'his', 'work', 'which', 'God', 'created', 'and', 'made', '.', 'These', 'are', 'the', 'generations', 'of', 'the', 'heavens', 'and', 'of', 'the', 'earth', 'when', 'they', 'were', 'created', ',', 'in', 'the', 'day', 'that', 'the', 'LORD', 'God', 'made', 'the', 'earth', 'and', 'the', 'heavens', ',', 'And', 'every', 'plant', 'of', 'the', 'field', 'before', 'it', 'was', 'in', 'the', 'earth', ',', 'and', 'every', 'herb', 'of', 'the', 'field', 'before', 'it', 'grew', ':', 'for', 'the', 'LORD', 'God', 'had', 'not', 'caused', 'it', 'to', 'rain', 'upon', 'the', 'earth', ',', 'and', 'there', 'was', 'not', 'a', 'man', 'to', 'till', 'the', 'ground', '.', 'But', 'there', 'went', 'up', 'a', '<unknown>', 'from', 'the', 'earth', ',', 'and', 'watered', 'the', 'whole', 'face', 'of', 'the', 'ground', '.', 'And', 'the', 'LORD', 'God', 'formed', 'man', 'of', 'the', 'dust', 'of', 'the', 'ground', ',', 'and', 'breathed', 'into', 'his', 'nostrils', 'the', 'breath', 'of', 'life', ';', 'and', 'man', 'became', 'a', 'living', 'soul', '.', 'And', 'the', 'LORD', 'God', 'planted', 'a', 'garden', 'eastward', 'in', 'Eden', ';', 'and', 'there', 'he', 'put', 'the', 'man', 'whom', 'he', 'had', 'formed', '.', 'And', 'out', 'of', 'the', 'ground', 'made', 'the', 'LORD', 'God', 'to', 'grow', 'every', 'tree', 'that', 'is', 'pleasant', 'to', 'the', 'sight', ',', 'and', 'good', 'for', 'food', ';', 'the', 'tree', 'of', 'life', 'also', 'in', 'the', 'midst', 'of', 'the', 'garden', ',', 'and', 'the', 'tree', 'of', 'knowledge', 'of', 'good', 'and', 'evil', '.', 'And', 'a', 'river', 'went', 'out', 'of', 'Eden', 'to', 'water', 'the', 'garden', ';', 'and', 'from', 'thence', 'it', 'was', 'parted', ',', 'and', 'became', 'into', 'four', 'heads', '.', 'The', 'name', 'of', 'the', 'first', 'is', '<unknown>', ':', 'that', 'is', 'it', 'which', 'compasseth', 'the', 'whole', 'land', 'of', 'Havilah', ',', 'where', 'there', 'is', 'gold', ';', 'And', 'the', 'gold', 'of', 'that', 'land', 'is', 'good', ':', 'there', 'is', '<unknown>', 'and', 'the', 'onyx', 'stone', '.', 'And', 'the', 'name', 'of', 'the', 'second', 'river', 'is', 'Gihon', ':', 'the', 'same', 'is', 'it', 'that', 'compasseth', 'the', 'whole', 'land', 'of', '<unknown>', '.', 'And', 'the', 'name', 'of', 'the', 'third', 'river', 'is', '<unknown>', ':', 'that', 'is', 'it', 'which', 'goeth', 'toward', 'the', 'east', 'of', 'Assyria', '.', 'And', 'the', 'fourth', 'river', 'is', 'Euphrates', '.', 'And', 'the', 'LORD', 'God', 'took', 'the', 'man', ',', 'and', 'put', 'him', 'into', 'the', 'garden', 'of', 'Eden', 'to', 'dress', 'it', 'and', 'to', 'keep', 'it', '.', 'And', 'the', 'LORD', 'God', 'commanded', 'the', 'man', ',', 'saying', ',', 'Of', 'every', 'tree', 'of', 'the', 'garden', 'thou', 'mayest', 'freely', 'eat', ':', 'But', 'of', 'the', 'tree', 'of', 'the', 'knowledge', 'of', 'good', 'and', 'evil', ',', 'thou', 'shalt', 'not', 'eat', 'of', 'it', ':', 'for', 'in', 'the', 'day', 'that', 'thou', 'eatest', 'thereof', 'thou', 'shalt', 'surely', 'die', '.', 'And', 'the', 'LORD', 'God', 'said', ',', 'It', 'is', 'not', 'good', 'that', 'the', 'man', 'should', 'be', 'alone', ';', 'I', 'will', 'make', 'him', 'an', 'help', 'meet', 'for', 'him', '.', 'And', 'out', 'of', 'the', 'ground', 'the', 'LORD', 'God', 'formed', 'every', 'beast', 'of', 'the', 'field', ',', 'and', 'every', 'fowl', 'of', 'the', 'air', ';', 'and', 'brought', 'them', 'unto', 'Adam', 'to', 'see', 'what', 'he', 'would', 'call', 'them', ':', 'and', 'whatsoever', 'Adam', 'called', 'every', 'living', 'creature', ',', 'that', 'was', 'the', 'name', 'thereof', '.', 'And', 'Adam', 'gave', 'names', 'to', 'all', 'cattle', ',', 'and', 'to', 'the', 'fowl', 'of', 'the', 'air', ',', 'and', 'to']\n"
     ]
    }
   ],
   "source": [
    "bible_map_word_to_freq = {}\n",
    "\n",
    "for word in bible:\n",
    "    if word in bible_map_word_to_freq:\n",
    "        bible_map_word_to_freq[word] += 1\n",
    "    else:\n",
    "        bible_map_word_to_freq[word] = 1\n",
    "\n",
    "bible = [\"<unknown>\" if bible_map_word_to_freq[word] < prune_freq else word for word in bible]\n",
    "print bible[1000:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change bible into an np array. In this case it has around 900k words. Therefore, it will be a (900k,) array.\n",
    "bible_seq = np.array(bible)\n",
    "\n",
    "bible_set = set(bible)\n",
    "bible_map_word_to_idx = {word : i for i, word in enumerate(bible_set)} # We have about 30k unique vocabularies.\n",
    "bible_map_idx_to_word = {i : word for i, word in enumerate(bible_set)} # We have about 30k unique vocabularies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4094\n",
      "4094\n",
      "4093\n"
     ]
    }
   ],
   "source": [
    "print len(bible_map_idx_to_word)\n",
    "print len(bible_set)\n",
    "max_val = 0\n",
    "for key in bible_map_word_to_idx:\n",
    "    max_val = max(max_val, bible_map_word_to_idx[key])\n",
    "print max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a numpy array, so we use h5py.\n",
    "with h5py.File(word_sequence_dest, 'w') as f:\n",
    "    f.create_dataset('bible_seq', data=bible_seq)\n",
    "# This is a python dict, so we use pickle.\n",
    "with open(word_mapping_dest, 'w') as f:\n",
    "    pickle.dump(bible_map_word_to_idx, f)\n",
    "with open(idx_mapping_dest, 'w') as f:\n",
    "    pickle.dump(bible_map_idx_to_word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
