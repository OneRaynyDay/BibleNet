{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tools.numerical_gradient import *\n",
    "from models.layers import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try out some simple functions for numerical_gradient. #\n",
    "\n",
    "We know the linear equation y = 3x should always return 3. Let's check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.99999999989\n"
     ]
    }
   ],
   "source": [
    "def linear(x, slope=3):\n",
    "    return slope*x\n",
    "\n",
    "slope = numerical_gradient_check_scalar(linear, 5)\n",
    "print slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.9999999   0.99999997]\n"
     ]
    }
   ],
   "source": [
    "def multi_quadratic(x):\n",
    "    return x[0]**2 + x[1]\n",
    "arr = np.array([2,2], float)\n",
    "\n",
    "slope = numerical_gradient_check_multivar(multi_quadratic, arr)\n",
    "print slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29.03938293   8.09431076]\n",
      "[[ 8.01086426  3.0040741 ]\n",
      " [ 8.01086426  3.0040741 ]]\n"
     ]
    }
   ],
   "source": [
    "def multi_cubic_field(x):\n",
    "    return np.array([x[0]**3 + x[1]**2, x[0]*2 + x[1]/12])\n",
    "arr = np.array([3,4], dtype=np.float32)\n",
    "\n",
    "def matrix_mult(x, b = np.array([[3,5],[2,1]])):\n",
    "    return x.dot(b)\n",
    "                \n",
    "vector_field = numerical_gradient_check_multivar(multi_cubic_field, arr)\n",
    "print vector_field\n",
    "\n",
    "arr = np.array([[3,4],[1,2]], dtype=np.float32)\n",
    "vector_field = numerical_gradient_check_multivar(matrix_mult, arr)\n",
    "print vector_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fw :  [[ 0.99999997  0.99999997  0.99999997]\n",
      " [ 1.99999995  1.99999995  1.99999995]]\n",
      "fx :  [[ 5.99999985  7.9999998 ]]\n",
      "fb :  [[ 0.99999997  0.99999997  0.99999997]]\n"
     ]
    }
   ],
   "source": [
    "def affine_transform(w, x, b):\n",
    "    return x.dot(w) + b\n",
    "\n",
    "x = np.array([[1,2]], float) # 1 x 2\n",
    "w = np.array([[3,2,1],[1,2,5]], float) # 2 x 3\n",
    "b = np.array([[1,5,7]], float) # 1 x 3\n",
    "\n",
    "fw = lambda w: affine_transform(w,x,b)\n",
    "fx = lambda x: affine_transform(w,x,b)\n",
    "fb = lambda b: affine_transform(w,x,b)\n",
    "\n",
    "vector_field = numerical_gradient_check_multivar(fw, w)\n",
    "print \"fw : \", vector_field\n",
    "vector_field = numerical_gradient_check_multivar(fx, x)\n",
    "print \"fx : \", vector_field\n",
    "vector_field = numerical_gradient_check_multivar(fb, b)\n",
    "print \"fb : \", vector_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# word_embedding_forward/backward #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 4) \n",
      "[[[3 4 7 1]\n",
      "  [3 4 7 1]\n",
      "  [1 5 9 4]]\n",
      "\n",
      " [[1 5 9 4]\n",
      "  [1 5 9 4]\n",
      "  [1 5 9 4]]\n",
      "\n",
      " [[4 3 2 5]\n",
      "  [3 4 7 1]\n",
      "  [4 3 2 5]]]\n"
     ]
    }
   ],
   "source": [
    "# Looks good to me\n",
    "ans = np.array([[[3, 4, 7, 1],\n",
    "                [3, 4, 7, 1],\n",
    "                [1, 5, 9, 4]],\n",
    "\n",
    "               [[1, 5, 9, 4],\n",
    "                [1, 5, 9, 4],\n",
    "                [1, 5, 9, 4]],\n",
    "\n",
    "               [[4, 3, 2, 5],\n",
    "                [3, 4, 7, 1],\n",
    "                [4, 3, 2, 5]]])\n",
    "\n",
    "x = np.array([[1,1,0], [0,0,0], [2,1,2]], int)\n",
    "words = np.array([[1,5,9,4],[3,4,7,1],[4,3,2,5]])\n",
    "arr = word_embedding_forward(words, x)\n",
    "\n",
    "assert np.array_equal(ans, arr)\n",
    "print arr.shape, \"\\n\", arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4) \n",
      "[[  7.  20.  13.  11.]\n",
      " [  4.   5.   9.   7.]\n",
      " [  4.   0.   1.   1.]]\n"
     ]
    }
   ],
   "source": [
    "dout = np.array([[[1,2,0,1],[3,2,9,1],[1,2,1,1]],\n",
    "                 [[3,9,2,4],[1,9,9,0],[2,0,1,6]],\n",
    "                 [[1,0,1,0],[0,1,0,5],[3,0,0,1]]])\n",
    "\n",
    "arr = word_embedding_backward(dout, words, x)\n",
    "ans = np.array([[  7.,  20.,  13.,  11.],\n",
    "               [  4.,   5.,   9.,   7.],\n",
    "               [  4.,   0.,   1.,   1.]])\n",
    "\n",
    "assert np.array_equal(ans, arr)\n",
    "print arr.shape, \"\\n\", arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh Vanilla RNN_step Layer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "\"\"\"\n",
    "prev_h = (N,H)\n",
    "x = (N, V)\n",
    "W_hh = (H,H)\n",
    "W_xh = (V,H)\n",
    "b = (H,)\n",
    "\"\"\"\n",
    "prev_h = np.random.random((3,5)) # N = 3, H = 5\n",
    "x = np.random.random((3,4)) # N = 3, V = 4\n",
    "W_hh = np.random.random((5,5)) # H = 5\n",
    "W_xh = np.random.random((4,5)) # V = 4, H = 5\n",
    "b = np.random.random((5,)) # H = 5\n",
    "\n",
    "res = rnn_step_forward(prev_h, W_hh, x, W_xh, b) # N = 3, H = 5\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dprev_h :  1.26232714804e-08\n",
      "dW_hh :  1.26096801212e-08\n",
      "dx :  1.26003102835e-08\n",
      "dW_xh :  1.26312391781e-08\n",
      "db :  1.25970797693e-08\n"
     ]
    }
   ],
   "source": [
    "# Backward\n",
    "fprev_h = lambda prev_h: rnn_step_forward(prev_h, W_hh, x, W_xh, b)\n",
    "fW_hh = lambda W_hh: rnn_step_forward(prev_h, W_hh, x, W_xh, b)\n",
    "fx = lambda x: rnn_step_forward(prev_h, W_hh, x, W_xh, b)\n",
    "fW_xh = lambda W_xh: rnn_step_forward(prev_h, W_hh, x, W_xh, b)\n",
    "fb = lambda b: rnn_step_forward(prev_h, W_hh, x, W_xh, b)\n",
    "\n",
    "dprev_h_num = numerical_gradient_check_multivar(fprev_h, prev_h)\n",
    "dW_hh_num = numerical_gradient_check_multivar(fW_hh, W_hh)\n",
    "dx_num = numerical_gradient_check_multivar(fx, x)\n",
    "dW_xh_num = numerical_gradient_check_multivar(fW_xh, W_xh)\n",
    "db_num = numerical_gradient_check_multivar(fb, b)\n",
    "\n",
    "dW_hh, dW_xh, dprev_h, dx, db = rnn_step_backward(prev_h, W_hh, x, W_xh, b, np.ones_like(res))\n",
    "print \"dprev_h : \", norm_loss(dprev_h, dprev_h_num)\n",
    "print \"dW_hh : \", norm_loss(dW_hh, dW_hh_num)\n",
    "print \"dx : \", norm_loss(dx, dx_num)\n",
    "print \"dW_xh : \", norm_loss(dW_xh, dW_xh_num)\n",
    "print \"db : \", norm_loss(db, db_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh Vanilla RNN Layer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "models/layers.py:161: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if h0 != None: # Supply an h0 state.\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "from tools.numerical_gradient import *\n",
    "from models.layers import *\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "h0 = (N,H)\n",
    "W_hh = (H,H)\n",
    "x = (N,T,D)\n",
    "W_xh = (D,H)\n",
    "b = (H,)\n",
    "\"\"\"\n",
    "N = 3\n",
    "D = 4\n",
    "H = 5\n",
    "T = 1\n",
    "\n",
    "h0 = np.random.random((N,H))\n",
    "W_hh = np.random.random((H,H))\n",
    "x = np.random.random((N,T,D))\n",
    "W_xh = np.random.random((D,H))\n",
    "b = np.random.random((H,))\n",
    "\n",
    "h = rnn_forward(x, W_xh, W_hh, b, h0)\n",
    "\n",
    "print h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW_hh :  1.26022016596e-08\n",
      "dW_xh :  1.26066582029e-08\n",
      "dx :  1.26172189348e-08\n",
      "db :  1.26088284757e-08\n",
      "dh0 :  1.26056472474e-08\n"
     ]
    }
   ],
   "source": [
    "# Backward\n",
    "fx = lambda x: rnn_forward(x, W_xh, W_hh, b, h0)\n",
    "fW_xh = lambda W_xh: rnn_forward(x, W_xh, W_hh, b, h0)\n",
    "fW_hh = lambda W_hh: rnn_forward(x, W_xh, W_hh, b, h0)\n",
    "fb = lambda b: rnn_forward(x, W_xh, W_hh, b, h0)\n",
    "fh0 = lambda h0: rnn_forward(x, W_xh, W_hh, b, h0)\n",
    "\n",
    "dx_num = numerical_gradient_check_multivar(fx, x)\n",
    "dW_xh_num = numerical_gradient_check_multivar(fW_xh, W_xh)\n",
    "dW_hh_num = numerical_gradient_check_multivar(fW_hh, W_hh)\n",
    "db_num = numerical_gradient_check_multivar(fb, b)\n",
    "dh0_num = numerical_gradient_check_multivar(fh0, h0)\n",
    "\n",
    "dW_hh, dW_xh, dx, db, dh0 = rnn_backward(x, W_xh, W_hh, b, h0, h, np.ones_like(h))\n",
    "print \"dW_hh : \", norm_loss(dW_hh, dW_hh_num)\n",
    "print \"dW_xh : \", norm_loss(dW_xh, dW_xh_num)\n",
    "print \"dx : \", norm_loss(dx, dx_num)\n",
    "print \"db : \", norm_loss(db, db_num)\n",
    "print \"dh0 : \", norm_loss(dh0, dh0_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine Layer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 7)\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "\"\"\"\n",
    "h = (N,H)\n",
    "W_hy = (H,D)\n",
    "b = (D,)\n",
    "\"\"\"\n",
    "h = np.random.random((3,5)) # N = 3, H = 5\n",
    "W_hy = np.random.random((5,7)) # H = 5, D = 7\n",
    "b = np.random.random((7,)) # D = 7\n",
    "\n",
    "res = affine_forward(h, W_hy, b) # N = 3, D = 7\n",
    "print res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx :  1.26304513777e-08\n",
      "dW_xh :  1.26317338729e-08\n",
      "db :  1.26310626518e-08\n"
     ]
    }
   ],
   "source": [
    "fh = lambda h: affine_forward(h, W_hy, b)\n",
    "fW_hy = lambda W_hy: affine_forward(h, W_hy, b)\n",
    "fb = lambda b: affine_forward(h, W_hy, b)\n",
    "\n",
    "dh_num = numerical_gradient_check_multivar(fh, h)\n",
    "dW_hy_num = numerical_gradient_check_multivar(fW_hy, W_hy)\n",
    "db_num = numerical_gradient_check_multivar(fb, b)\n",
    "\n",
    "dh, dW_hy, db = affine_backward(h, W_hy, b, np.ones_like(res))\n",
    "\n",
    "print \"dx : \", norm_loss(dh, dh_num)\n",
    "print \"dW_xh : \", norm_loss(dW_hy, dW_hy_num)\n",
    "print \"db : \", norm_loss(db, db_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Softmax Layer - One of the most important functions in Deep Learning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJ :  1.26316073922e-08\n"
     ]
    }
   ],
   "source": [
    "# Forward and backwards\n",
    "\"\"\"\n",
    "x = (N,D)\n",
    "y = (N,)\n",
    "\"\"\"\n",
    "x = np.random.random((3,4)) # N = 3, D = 4\n",
    "y = np.random.randint(4, size=3) # D = 4, N = 3\n",
    "\n",
    "fx = lambda x: softmax(x, y)[0]\n",
    "\n",
    "loss, dJ = softmax(x, y)\n",
    "dJ_num = numerical_gradient_check_multivar(fx, x)\n",
    "print \"dJ : \", norm_loss(dJ, dJ_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Layer - The other most important functions in Deep Learning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJ :  1.26399460897e-08\n"
     ]
    }
   ],
   "source": [
    "# Forward and backwards\n",
    "\"\"\"\n",
    "x = (N,D)\n",
    "y = (N,)\n",
    "\"\"\"\n",
    "x = np.random.random((3,5)) # N = 3, D = 5\n",
    "y = np.random.randint(5, size=3) # D = 5, N = 3\n",
    "\n",
    "fx = lambda x: SVM(x, y)[0]\n",
    "\n",
    "loss, dJ = SVM(x, y)\n",
    "dJ_num = numerical_gradient_check_multivar(fx, x)\n",
    "print \"dJ : \", norm_loss(dJ, dJ_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The entire RNN forward() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
